{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clone git repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning git@github.com:heysarver/double-entry-accounting.git to data/double-entry-accounting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'data/double-entry-accounting'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'double-entry-accounting'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clone_repo(github_repo):\n",
    "    repo_name = github_repo.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "    repo_path = f\"data/{repo_name}\"\n",
    "    print(f\"Cloning {github_repo} to {repo_path}\")\n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "\n",
    "    if not os.path.exists(repo_path):\n",
    "        subprocess.run([\"git\", \"clone\", github_repo, repo_path], check=True)\n",
    "    else:\n",
    "        print(f\"Repository {repo_name} already exists. Skipping clone.\")\n",
    "    \n",
    "    return repo_name\n",
    "\n",
    "clone_repo(\"git@github.com:heysarver/double-entry-accounting.git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Search for all files based on a list of file extensions (python only for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/double-entry-accounting/migrate.py', 'data/double-entry-accounting/run.py', 'data/double-entry-accounting/delete_test_data.py', 'data/double-entry-accounting/import_test_data.py', 'data/double-entry-accounting/migrations/env.py', 'data/double-entry-accounting/migrations/versions/202309071641-9cb1089a9def_add_ondelete_cascade.py', 'data/double-entry-accounting/migrations/versions/202309071654-4ab13a0bd1aa_allow_custom_txnids.py', 'data/double-entry-accounting/migrations/versions/202309071705-194466430716_add_views.py', 'data/double-entry-accounting/migrations/versions/202309071607-99d831242adc_initial_db.py', 'data/double-entry-accounting/app/__init__.py', 'data/double-entry-accounting/app/models.py', 'data/double-entry-accounting/app/config.py', 'data/double-entry-accounting/app/routes/transactions.py', 'data/double-entry-accounting/app/routes/accounts.py', 'data/double-entry-accounting/app/routes/utils.py', 'data/double-entry-accounting/app/seeds/__init__.py', 'data/double-entry-accounting/app/seeds/seeds.py']\n"
     ]
    }
   ],
   "source": [
    "def get_file_list(repo_name, file_extensions):\n",
    "    embed_files = []\n",
    "    file_extensions = file_extensions.split(',')\n",
    "    for root, dirs, files in os.walk(f\"data/{repo_name}\"):\n",
    "        for file in files:\n",
    "            if any(file.endswith(ext) for ext in file_extensions):\n",
    "                embed_files.append(os.path.join(root, file))\n",
    "    return embed_files\n",
    "\n",
    "files = get_file_list(\"double-entry-accounting\", \"py\")\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Read each file and extract a list of all functions and variables outside of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions:\n",
      "def get_engine():\n",
      "    try:\n",
      "        # this works with Flask-SQLAlchemy<3 and Alchemical\n",
      "        return current_app.extensions['migrate'].db.get_engine()\n",
      "    except TypeError:\n",
      "        # this works with Flask-SQLAlchemy>=3\n",
      "        return current_app.extensions['migrate'].db.engine\n",
      "\n",
      "\n",
      "\n",
      "def get_engine_url():\n",
      "    try:\n",
      "        return get_engine().url.render_as_string(hide_password=False).replace(\n",
      "            '%', '%%')\n",
      "    except AttributeError:\n",
      "        return str(get_engine().url).replace('%', '%%')\n",
      "\n",
      "\n",
      "\n",
      "def get_metadata():\n",
      "    if hasattr(target_db, 'metadatas'):\n",
      "        return target_db.metadatas[None]\n",
      "    return target_db.metadata\n",
      "\n",
      "\n",
      "\n",
      "def run_migrations_offline():\n",
      "    \"\"\"Run migrations in 'offline' mode.\n",
      "\n",
      "    This configures the context with just a URL\n",
      "    and not an Engine, though an Engine is acceptable\n",
      "    here as well.  By skipping the Engine creation\n",
      "    we don't even need a DBAPI to be available.\n",
      "\n",
      "    Calls to context.execute() here emit the given string to the\n",
      "    script output.\n",
      "\n",
      "    \"\"\"\n",
      "    url = config.get_main_option(\"sqlalchemy.url\")\n",
      "    context.configure(\n",
      "        url=url, target_metadata=get_metadata(), literal_binds=True\n",
      "    )\n",
      "\n",
      "    with context.begin_transaction():\n",
      "        context.run_migrations()\n",
      "\n",
      "\n",
      "\n",
      "def run_migrations_online():\n",
      "    \"\"\"Run migrations in 'online' mode.\n",
      "\n",
      "    In this scenario we need to create an Engine\n",
      "    and associate a connection with the context.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    # this callback is used to prevent an auto-migration from being generated\n",
      "    # when there are no changes to the schema\n",
      "    # reference: http://alembic.zzzcomputing.com/en/latest/cookbook.html\n",
      "    def process_revision_directives(context, revision, directives):\n",
      "        if getattr(config.cmd_opts, 'autogenerate', False):\n",
      "            script = directives[0]\n",
      "            if script.upgrade_ops.is_empty():\n",
      "                directives[:] = []\n",
      "                logger.info('No changes in schema detected.')\n",
      "\n",
      "    connectable = get_engine()\n",
      "\n",
      "    with connectable.connect() as connection:\n",
      "        context.configure(\n",
      "            connection=connection,\n",
      "            target_metadata=get_metadata(),\n",
      "            process_revision_directives=process_revision_directives,\n",
      "            **current_app.extensions['migrate'].configure_args\n",
      "        )\n",
      "\n",
      "        with context.begin_transaction():\n",
      "            context.run_migrations()\n",
      "\n",
      "\n",
      "\n",
      "Classes:\n"
     ]
    }
   ],
   "source": [
    "def extract_python_functions_and_classes(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    functions = []\n",
    "    classes = []\n",
    "    current_block = []\n",
    "    in_function = False\n",
    "    in_class = False\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(r'^def ', line):\n",
    "            functions.append(''.join(current_block))\n",
    "            current_block = [line]\n",
    "            in_function = True\n",
    "            in_class = False\n",
    "        elif re.match(r'^class ', line):\n",
    "            classes.append(''.join(current_block))\n",
    "            current_block = [line]\n",
    "            in_function = False\n",
    "            in_class = True\n",
    "        elif re.match(r'^\\S', line):\n",
    "            if in_function:\n",
    "                functions.append(''.join(current_block))\n",
    "                current_block = []\n",
    "                in_function = False\n",
    "            elif in_class:\n",
    "                classes.append(''.join(current_block))\n",
    "                current_block = []\n",
    "                in_class = False\n",
    "        elif in_function or in_class:\n",
    "            current_block.append(line)\n",
    "\n",
    "    if current_block:\n",
    "        if in_function:\n",
    "            functions.append(''.join(current_block))\n",
    "        elif in_class:\n",
    "            classes.append(''.join(current_block))\n",
    "\n",
    "    return functions, classes\n",
    "\n",
    "print(\"Functions:\")\n",
    "for f in functions:\n",
    "    print(f)\n",
    "\n",
    "print(\"Classes:\")\n",
    "for c in classes:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For each function, generate a short description using a code-trained model from huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. For each function, generate a short description using a code-trained model from huggingface.\n",
    "\n",
    "# 5. For each class, generate a short description using a code-trained model from huggingface.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
